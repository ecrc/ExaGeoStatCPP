extern "C" %{
/**
 * @copyright (c) 2023     King Abdullah University of Science and Technology (KAUST).
 * @copyright (c) 2023     The Universiy of Tennessee and The Universiy of Tennessee Research Foundation.
 *                         All rights reserved.
 **/

#include <runtime/parsec/ParsecHeader.h>
#include <runtime/parsec/JDFHelperFunctions.h>

%}

/* Globals
 */
apADesc           [ type = "parsec_tiled_matrix_t*" ]
apNormTile        [ type = "double *" ]
aNT               [ type = "int" ]
aUpperLower       [ type = "int" ]
aNormGlobal       [ type = "double" ]
apNorm            [ type = "double *" ]


/**************************************************
 *        generate diagonal tiles                 *
 **************************************************/
task(m, n)

// Execution space
m = 0 .. apADesc->mt-1
n = 0 .. apADesc->nt-1

// Parallel partitioning
:apADesc(m, n)

// Parameters
READ D <- apADesc(m, n)

BODY
{
    int ldd = BLKLDD(apADesc, m);
    int tempmm = m == apADesc->mt-1 ? apADesc->m - m * apADesc->mb : apADesc->mb;
    int tempnn = tempmm;

    /* Calcuate the global norm */
    int tid = es->th_id;
    double current_value = 0.0;
    apNormTile[n * aNT + m] = 0.0;

    for(int j = 0; j < apADesc->nb; j++) {
        for(int i = 0; i < apADesc->mb; i++) {
            current_value = ((double *) D)[j * apADesc->mb + i];
            apNormTile[n * aNT + m] += current_value * current_value;
        }
    }

    apNorm[tid] += apNormTile[n * aNT + m];
    apNormTile[n * aNT + m] = sqrt(apNormTile[n * aNT + m]);

    if( m - n >= aNT * PORTION_NORM )
        apNorm[tid] = 0.0;
}
END

extern "C" %{

/**
 * Generate matrix
 * @return the parsec object to schedule
 */
parsec_taskpool_t*
GetMatrixNorm_constructor(parsec_tiled_matrix_t *apADesc, double *apNormTmp, int aUpperLower, int aNT, double aNormGlobal, double *apNorm)
{

    /* Check input arguments */
    if (aUpperLower != PlasmaLower) {
        dplasma_error("STARSH_appr_New", "illegal value of uplo, should be PlasmaLower\n");
        return NULL;
    }

    parsec_GetMatrixNorm_taskpool_t *pTaskpool = parsec_GetMatrixNorm_new(apADesc, apNormTmp, aNT, aUpperLower, aNormGlobal, apNorm);

    return (parsec_taskpool_t*) pTaskpool;
}

/* Destructor */
void GetMatrixNorm_destructor(parsec_taskpool_t *apTaskpool)
{
    parsec_taskpool_free(apTaskpool);
}

/**
 * Generate matrix 
 */
double GetMatrixNorm(parsec_context_t *apContext, parsec_tiled_matrix_t *apADesc, double aNormGlobal, int aNT, int aUpperLower)
{

    /* Only for 1 vp */
    assert(apContext->nb_vp == 1);
    int nb_threads = apContext->virtual_processes[0]->nb_cores;
    double *pNormTmp = (double *) calloc(sizeof(double), nb_threads);

    /* Make sure norm_tile and norm_global is fresh */
    aNormGlobal = 0.0;
    double* pNormTile = (double*)malloc(aNT * aNT * sizeof(double));
    memset(pNormTile, 0, aNT * aNT * sizeof(double));

    parsec_taskpool_t *pTaskpool = GetMatrixNorm_constructor(apADesc, pNormTmp, aUpperLower, aNT, aNormGlobal, pNormTile);

    parsec_context_add_taskpool(apContext, pTaskpool);
    parsec_context_start(apContext);
    parsec_context_wait(apContext);
    GetMatrixNorm_destructor(pTaskpool);

    /* Reduce to the global norm */
    double norm_process = 0.0;
    for( int i = 0; i < nb_threads; i++ ) {
        norm_process += pNormTmp[i];
    }

    MPI_Allreduce(MPI_IN_PLACE, pNormTile, aNT * aNT, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
    MPI_Allreduce(&norm_process, &aNormGlobal, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
    aNormGlobal = sqrt(aNormGlobal);

    free(pNormTmp);
    return aNormGlobal;
}

%}
